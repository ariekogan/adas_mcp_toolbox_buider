services:
  backend:
    build:
      context: ./apps/backend
    environment:
      - NODE_ENV=production
      - PORT=4000
      - LLM_PROVIDER=${LLM_PROVIDER:-anthropic}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-sonnet-4-20250514}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4-turbo}
      - TENANTS_ROOT=/tenants
      # ADAS CORE connection (uses Tailscale IP for mac1 since services run on different machines)
      - ADAS_CORE_URL=${ADAS_CORE_URL:-http://100.125.67.116:4100}
      - CORE_MCP_URL=${CORE_MCP_URL:-http://100.125.67.116:4310/mcp}
      - CORE_MCP_SECRET=${CORE_MCP_SECRET:-7a0cf2318aa65a2b4bbe2e572a4152f7995fe7d8d52269e7201b9488b79cac62}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ${MEMORY_PATH:-./memory}/main:/tenants/main
      - ${MEMORY_PATH:-./memory}/testing:/tenants/testing
      - ${MEMORY_PATH:-./memory}/dev:/tenants/dev
    ports:
      - "${BACKEND_PORT:-4311}:4000"
      # Expose port range for dynamically spawned MCP servers
      - "8100-8110:8100-8110"
    restart: "no"
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 128M
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ulimits:
      nofile:
        soft: 1024
        hard: 2048

  frontend:
    build:
      context: ./apps/frontend
      args:
        - VITE_API_URL=http://localhost:${BACKEND_PORT:-4311}
    depends_on:
      - backend
    ports:
      - "${FRONTEND_PORT:-3312}:80"
    restart: "no"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          cpus: "0.1"
          memory: 64M
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

